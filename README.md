# ğŸ§  SENTIMENT ANALYSIS 2024/25 - UNICA

<p align="center">
  <a href="https://www.apache.org/licenses/LICENSE-2.0" target="_blank">
    <img src="https://img.shields.io/badge/License-Apache_2.0-4285F4?style=for-the-badge&logo=none&logoColor=white" alt="Apache License 2.0"/>
  </a>
  <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">
    <img src="https://img.shields.io/badge/Docs-CC_BY_4.0-FBBC05?style=for-the-badge&logo=none&logoColor=white" alt="CC BY 4.0 License"/>
  </a>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/c437885d-d304-4714-b4c2-0f47409ed226" alt="sentiment" width="600">
</p>

<p align="center">
  Project on <b>Binary Sentiment Analysis</b> using <b>Pretrained</b>, <b>Fine-tuned</b> and <b>Ensemble</b> Transformer Models.
</p>

---

> ## ğŸ“‘ Summary
> 01. [ğŸ§‘ğŸ»â€ğŸ“ Student](#student)  
> 02. [ğŸ“Œ Description](#description)  
> 03. [ğŸ“„ Notebooks Overview](#notebooks-overview)  
> 04. [ğŸ“ Project Structure](#project-structure)  
> 05. [ğŸ” Access to Hugging Face Models](#access-to-hugging-face-models)  
> 06. [ğŸš€ Installation](#installation)  
> 07. [ğŸ§ª Run: Model Training & Evaluation](#run-model-training--evaluation)  
> 08. [ğŸ“Š Metrics and Outputs](#metrics-and-outputs)  
> 09. [ğŸ–¥ï¸ Hardware and Limitations](#hardware-and-limitations)  
> 10. [ğŸ¤ Contributions](#contributions)  
> 11. [ğŸ“ Licenses](#licenses)  
> 12. [â“ How to Cite](#how-to-cite)

---

## 1. ğŸ§‘ğŸ»â€ğŸ“ Student <a name="student"></a>

#### Francesco Congiu  
> Student ID: 60/73/65300  
>  
>> E-Mail: f.congiu38@studenti.unica.it  

---

## 2. ğŸ“Œ Description <a name="description"></a>
This project investigates the impact of fine-tuning transformer-based models on the **Sentiment Analysis** task using the **IMDb dataset**.  
Three architectures are explored:

1. **Decoder-Only**: GPT-Neo  
2. **Encoder-Only**: BERT  
3. **Encoder-Decoder**: BART  

Additionally, we evaluate the performance of an **ensemble strategy** via **majority voting**.  
Both pretrained and fine-tuned versions are evaluated to compare generalization capabilities.

---

## 3. ğŸ“„ Notebooks Overview  <a name="notebooks-overview"></a>
> [!NOTE]
> Each notebook is self-contained and was provided for reproducibility.
> 
> Below a quick overview of each file:

| Notebook | Purpose |
|----------|---------|
| `train_models_from_scratch.ipynb` | Fine-tune each model and evaluate them individually |
| `ensemble_model_evaluation.ipynb` | Run ensemble predictions with majority voting |
| `models_plots_and_results.ipynb` | *(Coming soon)* Visual analysis, calibration and fairness plots |

---

## 4. ğŸ“ Project Structure <a name="project-structure"></a>

```plaintext
ğŸ“¦ sentiment-analysis-transformers/
â”œâ”€â”€ ğŸ“ data/                          # (optional: IMDb dataset if local)
â”œâ”€â”€ ğŸ“ experiments/
â”‚   â”œâ”€â”€ ğŸ“ plots/                     # Graphs and result plots
â”‚   â””â”€â”€ ğŸ“ results/
â”‚       â”œâ”€â”€ ğŸ“ evaluation/
â”‚       â”‚   â”œâ”€â”€ ğŸ“ finetuned/
â”‚       â”‚   â”‚   â”œâ”€â”€ bart-base-imdb.json
â”‚       â”‚   â”‚   â”œâ”€â”€ bert-base-uncased-imdb.json
â”‚       â”‚   â”‚   â””â”€â”€ gpt-neo-2.7b-imdb.json
â”‚       â”‚   â””â”€â”€ ğŸ“ pretrained/
â”‚       â”‚       â”œâ”€â”€ bart-base-imdb.json
â”‚       â”‚       â”œâ”€â”€ bert-base-uncased-imdb.json
â”‚       â”‚       â””â”€â”€ gpt-neo-2.7b-imdb.json
â”‚       â””â”€â”€ ğŸ“ validation/
â”‚           â””â”€â”€ ğŸ“ finetuned/
â”‚               â”œâ”€â”€ bart-base-imdb_metrics.json
â”‚               â”œâ”€â”€ bert-base-uncased-imdb_metrics.json
â”‚               â””â”€â”€ gpt-neo-2.7b-imdb_metrics.json
â”‚
â”œâ”€â”€ ğŸ“ models/                        # Folder for storing our models
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â”œâ”€â”€ train_models_from_scratch.ipynb
â”‚   â”œâ”€â”€ ensemble_model_evaluation.ipynb
â”‚   â””â”€â”€ plot_results_and_test_models.ipynb
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“ architectures/
â”‚   â”‚   â”œâ”€â”€ model_bart_base_imdb.py
â”‚   â”‚   â”œâ”€â”€ model_bert_base_uncased_imdb.py
â”‚   â”‚   â”œâ”€â”€ model_gpt_neo_2_7b_imdb.py
â”‚   â”‚   â””â”€â”€ model_ensemble_majority_voting.py
â”‚   â”œâ”€â”€ aggregate_json.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ download_models.py
â”‚   â”œâ”€â”€ ensemble_analysis.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ evaluate_ensemble.py
â”‚   â”œâ”€â”€ model_configs.py
â”‚   â”œâ”€â”€ model_configs_eval.py
â”‚   â”œâ”€â”€ model_factory.py
â”‚   â”œâ”€â”€ plot_results.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ upload_models.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## 5. ğŸ” Access to Hugging Face Models <a name="access-to-hugging-face-models"></a>

In order to download and use pretrained models from the ğŸ¤— Hugging Face Hub (like `bert-base-uncased`, `gpt-neo-2.7B`, or `bart-base`), youâ€™ll need to authenticate.

### 5.1 ğŸªª How to get your Hugging Face Token

1. Visit [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
2. Click **New Token**, choose role `Read` and generate it
3. Copy the token to your clipboard

When running the notebook, youâ€™ll be prompted to enter your token via:
```python
from huggingface_hub import notebook_login
notebook_login()
```
> [!NOTE]
> Run this manually in the first cell of the notebook if not already included. You only need to do this once per environment or session.

---

## 6. ğŸš€ Installation <a name="installation"></a>
Install requirements for any notebook as needed. For local runs, Python â‰¥ 3.8 is required.
> [!NOTE]
> For each notebook, you can use a dedicated environment to keep dependencies isolated.

---

## 7. ğŸ§ª Run: Model Training & Evaluation <a name="run-model-training--evaluation"></a>

### 7.1 ğŸ“˜ `train_models_from_scratch.ipynb`
The notebook performs the entire process of analyzing the performance of pre-trained and fine-tuned models on the **Sentiment Analysis** task with the IMDb dataset. The following are the main steps write in the first notebook:

#### 7.1.1 âš™ï¸ Environment Setup

```bash
!nvidia-smi          # GPU verification
%ls                  # Checking the files present
```

#### 7.1.2 ğŸ”„ Cloning the repository
```bash
!test -d DLA_LLMSANALYSIS && rm -rf DLA_LLMSANALYSIS
!git clone https://github.com/wakaflocka17/DLA_LLMSANALYSIS.git
%cd DLA_LLMSANALYSIS
```

#### 7.1.3 ğŸ Creation and activation of the virtual environment
```bash
!pip install virtualenv
!python -m virtualenv venv
!source venv/bin/activate
```

#### 7.1.4 ğŸ“¦ Installing dependencies
```bash
!venv/bin/pip install -r requirements.txt
```

#### 7.1.5 ğŸ” HuggingFace Login
```python
from huggingface_hub import notebook_login
notebook_login()
```

#### 7.1.6 ğŸ§  Models training and evaluation
##### ğŸ”¹ **BERT**
```python
# Training
!venv/bin/python main.py --model_config_key bert_base_uncased --mode train

# Evaluation - pretrained
!venv/bin/python main.py --model_config_key bert_base_uncased --mode eval --eval_type pretrained --output_json_path "results/evaluation/pretrained/bert-base-uncased-imdb.json"

# Evaluation - fine-tuned
!venv/bin/python main.py --model_config_key bert_base_uncased --mode eval --eval_type fine_tuned --output_json_path "results/evaluation/finetuned/bert-base-uncased-imdb.json"
```

##### ğŸ”¹ **BART**
```python
# Training
!venv/bin/python main.py --model_config_key bart_base --mode train

# Evaluation - pretrained
!venv/bin/python main.py --model_config_key bart_base --mode eval --eval_type pretrained --output_json_path "results/evaluation/pretrained/bart-base-imdb.json"

# Evaluation - fine-tuned
!venv/bin/python main.py --model_config_key bart_base --mode eval --eval_type fine_tuned --output_json_path "results/evaluation/finetuned/bart-base-imdb.json"
```

##### ğŸ”¹ **GPT-Neo**
```python
# Training
!venv/bin/python main.py --model_config_key gpt_neo_2_7b --mode train

# Evaluation - pretrained
!venv/bin/python main.py --model_config_key gpt_neo_2_7b --mode eval --eval_type pretrained --output_json_path "results/evaluation/pretrained/gpt-neo-2.7b-imdb.json"

# Evaluation - fine-tuned
!venv/bin/python main.py --model_config_key gpt_neo_2_7b --mode eval --eval_type fine_tuned --output_json_path "results/evaluation/finetuned/gpt-neo-2.7b-imdb.json"
```

#### 7.1.7 â˜ï¸ Uploading to Hugging Face Hub
```python
!venv/bin/python src/upload_models.py --only bert-base-uncased-imdb
!venv/bin/python src/upload_models.py --only bart-base-imdb
!venv/bin/python src/upload_models.py --only gpt-neo-2.7B-imdb
```

### 7.2 ğŸ‘¥ `ensemble_model_evaluation.ipynb`
This notebook performs ensemble **Majority Voting** among the fine-tuned models for the **Sentiment Analysis** task on the IMDb dataset. Following are the steps performed:

#### 7.2.1 âš™ï¸ Environment Setup

```bash
!nvidia-smi          # GPU verification
%ls                  # Checking the files present
```

#### 7.2.2 ğŸ”„ Cloning the repository
```bash
!test -d DLA_LLMSANALYSIS && rm -rf DLA_LLMSANALYSIS
!git clone https://github.com/wakaflocka17/DLA_LLMSANALYSIS.git
%cd DLA_LLMSANALYSIS
```

#### 7.2.3 ğŸ Creation and activation of the virtual environment
```bash
!pip install virtualenv
!python -m virtualenv venv
!source venv/bin/activate
```

#### 7.2.4 ğŸ“¦ Installing dependencies
```bash
!venv/bin/pip install -r requirements.txt
```

#### 7.2.5 ğŸ” HuggingFace Login
```python
from huggingface_hub import notebook_login
notebook_login()
```

#### 7.2.6 â¬‡ï¸ Downloading Fine-Tuned models
##### ğŸ”¹ **BERT**
```python
# Download
!venv/bin/python src/download_models.py bert_base_uncased
```

##### ğŸ”¹ **BART**
```python
# Download
!venv/bin/python src/download_models.py bart_base
```

##### ğŸ”¹ **GPT-Neo**
```python
# Download
!venv/bin/python src/download_models.py gpt_neo_2_7b
```

#### 7.2.7 ğŸ§  Ensemble model evaluation
```python
!venv/bin/python src/upload_models.py --only majority-voting-imdb
```

#### 7.2.8 â˜ï¸ Uploading the Ensemble model to Hugging Face Hub
```python
!venv/bin/python src/upload_models.py --only majority-voting-imdb
```

### 7.3 ğŸ“Š `models_plots_and_results.ipynb`

---

## 8. ğŸ“Š Metrics and Outputs <a name="metrics-and-outputs"></a>

### 8.1 ğŸ“‘ Description
Each model evaluation is based on the following metrics:

| Metric      | Description                                      | Formula (Simplified)                            |
|-------------|--------------------------------------------------|-------------------------------------------------|
| Accuracy    | Overall correctness of the model                 | (TP + TN) / (TP + TN + FP + FN)                 |
| Precision   | How many predicted positives are correct         | TP / (TP + FP)                                  |
| Recall      | Ability to detect all true positives             | TP / (TP + FN)                                  |
| F1-Score    | Harmonic mean of precision and recall            | 2 Ã— (Precision Ã— Recall) / (Precision + Recall) |

> Where:
> - **TP** = True Positives  
> - **TN** = True Negatives  
> - **FP** = False Positives  
> - **FN** = False Negatives  

### 8.2 ğŸ“‚ Output Format

The evaluation metrics are saved as `.json` files for each model in the following format:

```json
{
  "accuracy": 0.91,
  "precision": 0.90,
  "recall": 0.91,
  "f1": 0.90
}
```

---

## 9. ğŸ–¥ï¸ Hardware and Limitations <a name="hardware-and-limitations"></a>
> [!NOTE]
> ğŸ§ª All training and evaluation were conducted on **Google Colab Pro+** with the following setup:
> - **Runtime environment**: Google Colab Pro+  
> - **GPU**: NVIDIA A100 (40GB VRAM)  
> - **RAM**: High-RAM Instance (â‰ˆ 52 GB)  
> - **Backend**: PyTorch with CUDA

> [!WARNING]
> - Training **GPT-Neo** locally (especially on CPU or low-VRAM GPU) may be extremely slow or unstable
> - If using Apple Silicon (M1/M2/M3/M4), consider the **MPS backend** but expect slower inference on large models

---

## 10. ğŸ¤ Contributions <a name="contributions"></a>
Feel free to contribute to the project! ğŸ’¡  
We welcome improvements, especially in the following areas:
- Adding new Transformer models (e.g. T5, DeBERTa, DistilBERT)
- Improving ensemble strategies (voting, stacking, etc.)
- Suggesting or implementing new evaluation metrics (e.g. calibration, fairness, coverage@k)

### 10.1 ğŸ“Œ How to Contribute <a name="how-to-cite"></a>

1. Fork the repository
2. Create a new branch:
   ```bash
   git checkout -b feature-name
   ```
3. Commit your changes:
   ```bash
   git commit -m "Add new evaluation metric"
   ```
4. Push the branch:
   ```bash
   git push origin feature-name
   ```
5. Open a Pull Request on GitHub
> ğŸ“¬ Weâ€™ll review your proposal and get back to you as soon as possible!

---

## 11. ğŸ“ Licenses <a name="licenses"></a>
> [!NOTE]
> **Code**: This repository's source code is licensed under the [Apache License 2.0](./LICENSE). You can read more at [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)
>
> **Documentation**: All documentation, including this README, is licensed under the [Creative Commons Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/). See the full text in the [LICENSE_DOCS](./LICENSE_DOCS) file.


---

## 12. â“ How to Cite
```bibtex
@misc{Sentiment-Project,
author       = {Francesco Congiu},
title        = {Sentiment Analysis with Pretrained, Fine-tuned and Ensemble Transformer Models},
howpublished = {\url{https://github.com/wakaflocka17/DLA_LLMSANALYSIS}},
year         = {2025}
}
```